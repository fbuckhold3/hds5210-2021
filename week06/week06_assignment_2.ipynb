{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 6 Exercises\n",
    "\n",
    "_McKinney 6.1_\n",
    "\n",
    "There are multiple ways to solve the problems below.  You can use any one of several approaches.  For example, you can read CSV files using Pandas or the csv module.  Your score won't depend on which modules you choose to use unless explicitly noted below, but your programming style will still matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 30.1 List of Allergies\n",
    "\n",
    "In the /data directory on the Jupyter server, there is a file called `allergies.json` that contains a list of patient allergies.  It is taken from sample data provided by the EHR vendor, Epic, here: https://open.epic.com/Clinical/Allergy\n",
    "\n",
    "Take some time to look at the structure of the file.  You can open it directly in Jupyter by clicking the _Home_ icon, then the _from_instructor_ folder, and then the _data_ folder.\n",
    "\n",
    "Within the file, you'll see that it is a dictionary with many items in it.  One of those items is called `entry` and that item is a list of things.  You can tell that because the item name is immediately followed by an opening square bracket, signifying the start of a list.  It's line 11 of the file: `  \"entry\": [`\n",
    "\n",
    "Write a function named `allergy_count(json_file)` that takes as one parameter the name of the JSON file and returns an integer number of entries in that file.  Your function should open the file, read the json into a Python object, and return how many items there are in the list of `entry`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "ALLERGIES_FILE=\"/data/allergies.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def allergy_count(json_file):\n",
    "    \"\"\"(str)_>int\n",
    "    This function takes a file name and reads the JSON from that file. \n",
    "    It assumes the file structure contains a dictionary with a\n",
    "    key of 'entry' whose value is a list of allergies.\n",
    "    \n",
    "    This function returns the length of that list of entries.\"\"\"\n",
    "    \n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "    \n",
    "    return len(allergies['entry'])\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def allergy_count(json_file):\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    return(len(allergies.get('entry')))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allergy_count(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q1-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(allergy_count(ALLERGIES_FILE)) == int\n",
    "assert allergy_count(ALLERGIES_FILE) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30.2 Number of Patients\n",
    "\n",
    "If you dig a little bit deaper into this list of allergies, you'll see that each result has a patient associated with it.  Create a funcation called `patient_count(json_file)` that will count how many unique patients we have in this JSON structure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\"Scratch\" cell:\n",
    "with open(ALLERGIES_FILE) as f:\n",
    "    allergies = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = allergies.get('entry')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jason Argonaut\n"
     ]
    }
   ],
   "source": [
    "patient = entry.get('resource').get('patient').get('display')\n",
    "print(patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "def patient_count(json_file):\n",
    "    \"\"\"(str)->int\n",
    "    This function reads the JSON-structured information from the file\n",
    "    and identifies how many different (unique) patients for which there\n",
    "    are allergies. This function returns the number of unique patients.\n",
    "    \"\"\"\n",
    "    with open(ALLERGIES_FILE) as f:\n",
    "        allergies = json.load(f) \n",
    "    \n",
    "    patients = set()\n",
    "    \n",
    "    for allergy in allergies.get('entry'):\n",
    "        patient = allergy.get('resource').get('patient').get('display')\n",
    "        patients.add(patient)\n",
    "        \n",
    "    return len(patients)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def patient_count(json_file):\n",
    "    patients = set()\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    for entry in allergies.get('entry'):\n",
    "        resource = entry.get('resource')\n",
    "        patient = resource.get('patient')\n",
    "        name = patient.get('display')\n",
    "        patients.add(name)\n",
    "        \n",
    "    return patients\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jason Argonaut', 'Paul Boal'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_count(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30.3 How Many Allergies per Patient\n",
    "\n",
    "Although each entry is a separate allergy, several of them are for the same patient.  Write a function called `allergy_per_patient(json_file)` that counts up how many allergies each patient has.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def allergy_per_patient(json_file):\n",
    "    \"\"\"(str)->dict\"\"\"\n",
    "    with open(ALLERGIES_FILE) as f:\n",
    "        allergies = json.load(f) \n",
    "    \n",
    "    patient_allergies = {}\n",
    "    \n",
    "    for allergy in allergies.get('entry'):\n",
    "        patient = allergy.get('resource').get('patient').get('display')\n",
    "        if patient in patient_allergies:\n",
    "            patient_allergies[patient] += 1\n",
    "        else: \n",
    "            patient_allergies[patient] = 1\n",
    "        \n",
    "    return len(patients)    \n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def allergy_per_patient(json_file):\n",
    "    patients = {}\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    for entry in allergies.get('entry'):\n",
    "        resource = entry.get('resource')\n",
    "        patient = resource.get('patient')\n",
    "        name = patient.get('display')\n",
    "        patients[name] = patients.setdefault(name,0) + 1\n",
    "        \n",
    "    return patients\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jason Argonaut': 3, 'Paul Boal': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allergy_per_patient(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-question",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 30.4 Patient Allergies and Reaction\n",
    "\n",
    "You'll see in the file that each of the items in the `entry` list have several other attributes including a patient name, substance text representation, and a reaction manifestation.  Create a function named `allergy_list(json_file)` that will create an output list that has patient name, allergy, and reaction for each `entry`.  The actual result you should get will be:\n",
    "\n",
    "```python\n",
    "[['Jason Argonaut', 'PENICILLIN G', 'Hives'],\n",
    " ['Paul Boal', 'PENICILLIN G', 'Bruising'],\n",
    " ['Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS', 'Itching'],\n",
    " ['Jason Argonaut', 'STRAWBERRY', 'Anaphylaxis']]\n",
    "```\n",
    "\n",
    "You'll notice that the reaction and the manifestation of that action are lists.  You only need to capture the first reaction and the first manifestation of the action.  That is, if there is a list of things, just output the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "### Create list -> name, substance, reaction; buried in 'entry' which is the clue - navigate the structure...\n",
    "def allergy_list(json_file):\n",
    "    \"\"\"(str)->list\n",
    "    Calls up a .json file to output a list of lists noting the pateint, \n",
    "    drug, and reaction to drug. If multiple reactions will pull the first.\n",
    "\n",
    "    \"\"\"\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "    with open(ALLERGIES_FILE) as f:\n",
    "        allergies = json.load(f) \n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    for allergy in allergies.get('entry'):\n",
    "        patient = allergy.get('resource').get('patient').get('display')\n",
    "        drug = allergy.get('resource').get('substance').get('text')\n",
    "        reactions = allergy.get('resource').get('reaction')\n",
    "        for reaction in reactions:\n",
    "            manifestation = reaction.get('manifestation')\n",
    "            for m in manifestation:\n",
    "                if m == manifestation[0]:\n",
    "                    manifest = m.get('text')\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "        output.append([patient, drug, manifest])\n",
    "        \n",
    "    return output\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q2-tests",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "output=[['Jason Argonaut', 'PENICILLIN G', 'Hives'],\n",
    " ['Paul Boal', 'PENICILLIN G', 'Bruising'],\n",
    " ['Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS', 'Itching'],\n",
    " ['Jason Argonaut', 'STRAWBERRY', 'Anaphylaxis']]\n",
    "\n",
    "assert allergy_list(ALLERGIES_FILE) == output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3-question",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 30.5 Allergy Reaction\n",
    "\n",
    "Write a function called `allergy_reaction(json_file,patient,substance)` that takes three parameter and returns the reaction that will happen if the patient takes the specified substance.  Solve this, in part, by calling your `allergy_list` function inside your new `allergy_reaction` function.\n",
    "\n",
    "If the substance is not found in the allergy list, the function should return None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "### call up function to return reaction to substance. Could use code from above...\n",
    "### BEGIN SOLUTION\n",
    "def allergy_reaction(json_file,patient,substance):\n",
    "    \"\"\" (str, str, str) -> int\n",
    "    Calls up a json file and takes variables that will be present to check against\n",
    "    a previous allergy function (allergy_list).\n",
    "    >>> allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'PENICILLIN G')\n",
    "    'Hives'\n",
    "    >>> allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS')\n",
    "    'Itching'\n",
    "    >>> allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'STRAWBERRY')\n",
    "    'Anaphylaxis'\n",
    "    >>> allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'PENICILLIN')\n",
    "    None\n",
    "    >>> allergy_reaction(ALLERGIES_FILE, 'Paul Boal', 'PENICILLIN G')\n",
    "    'Bruising'\n",
    "    \"\"\"\n",
    "    \n",
    "    allergies = allergy_list(ALLERGIES_FILE)\n",
    "    output = (None)\n",
    "    for allergy in allergies:\n",
    "        pat = allergy[0]\n",
    "        subs = allergy[1]\n",
    "        react = allergy [2]\n",
    "        \n",
    "        if pat == patient:\n",
    "            \n",
    "            if subs == substance:\n",
    "                output = react\n",
    "        \n",
    "            else:\n",
    "                pass\n",
    "       \n",
    "    return output\n",
    "            \n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q3-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'PENICILLIN G') == 'Hives'\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS') == 'Itching'\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'STRAWBERRY') == 'Anaphylaxis'\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'PENICILLIN') == None\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Paul Boal', 'PENICILLIN G') == 'Bruising'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Stretch (Extra) Problems\n",
    "\n",
    "Work on either of the stretch problems below can earn you up to 25 free points toward the midterm assignment.  That is, if you complete one of these extra problems successfully, you can skip 1 of the problems that will appear on the midterm exam coming up next week.\n",
    "\n",
    "The midterm will be distribute this Saturday 3/13.\n",
    "\n",
    "This assignment is due on Sunday 3/14.  If you are trying for one of these extra problems Slack me, and I'll provide you feedback on how you did on these before end of day Monday 3/15.  That way you can choose what to complete on the midterm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### STRETCH for March 2021 - For those looking for an additional challenge\n",
    "\n",
    "As I've mentioned in class, CMS is now enforcing a rule around price transparency.  Every facility that take Medicare payments is required to publish a \"machine readable\" file with it's pricing infomration for a number of common procedures across all of the payers they work with.  There are two examples of such files in the `/data/` directory: `whiteriver.json` and `saline.xml`.\n",
    "\n",
    "If you want to compare contracted prices across these two hospitals, you'll need to read in the information from both of those files into some kind of data structure, then merge the data together from those two files.  See what you can do.\n",
    "\n",
    "See if you can create an output file that has the following fields:\n",
    "* HOSPITAL\n",
    "* PROCEDURE_CODE\n",
    "* PAYER\n",
    "* AMOUNT\n",
    "\n",
    "If you choose to work on this, you may get stuck at some point and you won't know if you're _doing it right_. Make some assumptions. Document your questions in this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "STANDARD_CHARGES=HOME+\"/from_instructor/data/saline.xml\"\n",
    "\n",
    "path = STANDARD_CHARGES\n",
    "with open(path) as f:\n",
    "    xml = objectify.parse(f)\n",
    "\n",
    "std_charges = xml.getroot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hospitals = []\n",
    "\n",
    "for child in std_charges.getchildren():\n",
    "    Hospitals.append(str(child.attrib))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"{'Name': 'SALINE MEMORIAL HOSPITAL'}\"]\n"
     ]
    }
   ],
   "source": [
    "print(Hospitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facility : {'Name': 'SALINE MEMORIAL HOSPITAL'}\n"
     ]
    }
   ],
   "source": [
    "for child in std_charges.getchildren():\n",
    "    print(child.tag + \" : \" + str(child.attrib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### STRETCH from March 2020 - For those looking for an additional challenge\n",
    "\n",
    "The Coronavirus is creating quite the stir right now.  There are some sources suggesting that trends show it is going to be significantly more serious than SARS was back in the 2002 timeframe.  Here's one visualization trying to demonstrate that: https://www.reddit.com/r/China_Flu/comments/ev2b4v/i_updated_some_charts_comparing_this_outbreak/\n",
    "\n",
    "Someone on Kaggle has generously already compiled a dataset based on information from Johns Hopkins about the Coronavirus outbreak.  https://www.kaggle.com/brendaso/2019-coronavirus-dataset-01212020-01262020  Create a Kaggle account, if you don't already have one.  Download this data set and then upload it to your Jupyter Home folder.  (The \"up arrow\" button is for uploading a file.)\n",
    "\n",
    "Use Python's built-in `csv` module to read the data from this file and generate the following information: **what are the total confirmed cases in all of Mainland China as of the latest information in the data set?**  Some important things to note:\n",
    "* Each entry for a given city has the **cumulative** number of cases.  So that column is not additive (it cannot be summed).  You'll have to find a way to filter your data for the last day for each city, then total those up.\n",
    "* If you choose to parse the date column, you will want to lookup how to do that using Python's `datetime` module.  Especially the `strptime` function.  https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior  Hint: you can parse a date string in the format 2/17/2020 using the code below.  This link will tell you what things like `%m` and `%Y` mean.\n",
    "\n",
    "```\n",
    "from datetime import datetime\n",
    "d = datetime.strptime('2/17/2020', '%m/%d/%Y')\n",
    "```\n",
    "\n",
    "If you want to take this another step, **create a list of tuples that contain (observate date, total confirmed) totalled over all locations represented in the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submitting Your Work\n",
    "\n",
    "In order to submit your work, you'll need to use the `git` command line program to **add** your homework file (this file) to your local repository, **commit** your changes to your local repository, and then **push** those changes up to github.com.  From there, I'll be able to **pull** the changes down and do my grading.  I'll provide some feedback, **commit** and **push** my comments back to you.  Next week, I'll show you how to **pull** down my comments.\n",
    "\n",
    "To run through everything one last time and submit your work:\n",
    "1. Use the `Kernel` -> `Restart Kernel and Run All Cells` menu option to run everything from top to bottom and stop here.\n",
    "2. Save this note with Ctrl-S (or Cmd-S)\n",
    "2. Skip down to the last command cell (the one starting with `%%bash`) and run that cell.\n",
    "\n",
    "If anything fails along the way with this submission part of the process, let me know.  I'll help you troubleshoort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "DO NOT REMOVE THIS LINE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-cef8011cb395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DO NOT REMOVE THIS LINE\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: DO NOT REMOVE THIS LINE"
     ]
    }
   ],
   "source": [
    "assert False, \"DO NOT REMOVE THIS LINE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating 9bc66a5..982c93a\n",
      "Fast-forward\n",
      " week04/feedback.md | 22 ++++++++++++++++++++++\n",
      " 1 file changed, 22 insertions(+)\n",
      " create mode 100644 week04/feedback.md\n",
      "[main 6b3d777] Submitting the week 6 programming assignment\n",
      " 2 files changed, 808 insertions(+), 5 deletions(-)\n",
      " create mode 100644 week06/week06_assignment_2.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From github.com:fbuckhold3/hds5210-2021\n",
      "   9bc66a5..982c93a  main       -> origin/main\n",
      "To github.com:fbuckhold3/hds5210-2021.git\n",
      "   982c93a..6b3d777  main -> main\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git pull\n",
    "git add week06_assignment_2.ipynb\n",
    "git commit -a -m \"Submitting the week 6 programming assignment\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "If the message above says something like _Submitting the week 6 programming assignment_ or _Everything is up to date_, then your work was submitted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
